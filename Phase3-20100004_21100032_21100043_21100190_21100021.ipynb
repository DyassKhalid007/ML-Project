{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import python_speech_features as mfcc\n",
    "from scipy.io.wavfile import read\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd() #this is the current working directory\n",
    "#1st row of confusion matrix will represent male and 2nd will represent female\n",
    "genderDict = {'M':0,'F':1}\n",
    "speakerDict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pushing the indexes to 0 to redue the size of one hot vector so 1st speaker will have 0th index and so on\n",
    "# in the confusion matrix and classification report\n",
    "for i in range(1,143):\n",
    "    speakerDict[i] = i-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoader(object):\n",
    "    '''data loader class to load the data from the dictionary for both problems'''\n",
    "    \n",
    "    def __init__(self,problem,scaling=0):\n",
    "        '''initializing directories based on problem and specifying whether scaling is required or not'''\n",
    "        self.problem = problem \n",
    "        if self.problem==0:\n",
    "            #if problem is of gender recognition\n",
    "            self.DIR = \"\\\\Gender_Recognition\\\\\"\n",
    "        elif self.problem==1:\n",
    "            #if problem is of speaker recognition\n",
    "            self.DIR = \"\\\\Speaker_Recognition\\\\\"\n",
    "        else:\n",
    "            #if problem is none raise error\n",
    "            print(\"Values can only be 0 or 1\")\n",
    "            raise NotImplementedError(0)\n",
    "        #setting the scaling variable\n",
    "        self.scaling=scaling\n",
    "        \n",
    "    def returnData(self):\n",
    "        '''function to return the processed data and scale it if scaling is set'''\n",
    "        ###Naming conventions for train/test/val data XTrain/XTest\n",
    "        self.XTrain,self.YTrain = self.dataLoader(\"Train\",self.problem)\n",
    "        self.XTest,self.YTest = self.dataLoader(\"Test\",self.problem)\n",
    "\n",
    "        #Doing feature scaling if self.scaling is true \n",
    "        #Ignoring the bias term as that will just 0 it\n",
    "        mean = np.mean(self.XTrain[:,1:],axis=0)\n",
    "        std = np.std(self.XTrain[:,1:],axis=0)\n",
    "        #if scaling needs to be done\n",
    "        if self.scaling:\n",
    "            self.XTrain[:,1:] = (self.XTrain[:,1:]-mean)/std\n",
    "            self.XTest[:,1:] = (self.XTest[:,1:]-mean)/std\n",
    "        #converting to one hot enocding vectors\n",
    "        return (self.XTrain,self.YTrain,self.XTest,self.YTest)\n",
    "\n",
    "    def returnHotEncodings(self):\n",
    "        '''function to return one hot encodings of the data'''\n",
    "        return (self.YTrainOne,self.YTestOne,self.YValOne)\n",
    "\n",
    "    def get_MFCC(self,audio, sr):\n",
    "        '''blackbox function provided by the TA'''\n",
    "        features = mfcc.mfcc(audio, sr, 0.025, 0.01, 13, appendEnergy = True)\n",
    "        return np.mean(features, axis=0)\n",
    "\n",
    "    def dataLoader(self,dirName,problem):\n",
    "        '''function to load data depending on the problem'''\n",
    "        #if problem is gender recognition\n",
    "        if problem==0:\n",
    "            labels = []\n",
    "            data = []\n",
    "            names = []\n",
    "            for name in glob.glob(pwd+self.DIR+str(dirName)+\"\\\\*\"):\n",
    "               #label is M or F which is last word of file\n",
    "                label = name[-1]\n",
    "                #reading the wave files in the directory\n",
    "                for subnames in glob.glob(name+\"\\\\*\"):\n",
    "                    #convertin the wave files to features and appending\n",
    "                    sr, audio = read(subnames)\n",
    "                    features =self.get_MFCC(audio, sr) #adding the bias term\n",
    "                    data.append(features)\n",
    "                    #converting labels to 0/1 depending upon genderDict\n",
    "                    labels.append(genderDict[label])\n",
    "                    names.append(subnames)\n",
    "        #if problem is speaker recognition\n",
    "        if problem==1:\n",
    "            labels = []\n",
    "            data = []\n",
    "            names = []\n",
    "            for name in glob.glob(pwd+self.DIR+str(dirName)+\"\\\\*\"):\n",
    "                #using regex capture groups to read the speaker identity\n",
    "                pattern = re.search(\"([0-9]{3})\",name)\n",
    "                label = int(pattern.group(1))\n",
    "                #reading the wave files in the directory\n",
    "                for subnames in glob.glob(name+\"\\\\*\"):\n",
    "                    #converting to features and appending\n",
    "                    sr, audio = read(subnames)\n",
    "                    features =np.append(1 ,self.get_MFCC(audio, sr)) #adding the bias term\n",
    "                    data.append(features)\n",
    "                    #converting to labels depending upon the speaker dict\n",
    "                    labels.append(speakerDict[label])\n",
    "                    names.append(subnames)\n",
    "        #returning the data\n",
    "        return (np.array(data),np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading for gender recognition problem\n",
    "loaderp1 = dataLoader(0)\n",
    "XTrainp1,YTrainp1,XTestp1,YTestp1 = loaderp1.returnData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading for speaker recognition problem\n",
    "loaderp2 = dataLoader(1)\n",
    "XTrainp2,YTrainp2,XTestp2,YTestp2 = loaderp2.returnData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''class to train mlp,svm and gnb'''\n",
    "    \n",
    "    def __init__(self,XTrain,YTrain,XTest,YTest,problem):\n",
    "        '''function to set variables for project part 3'''\n",
    "        self.XTrain = XTrain\n",
    "        self.YTrain = YTrain\n",
    "        self.XTest = XTest\n",
    "        self.YTest = YTest\n",
    "        #problem 0 is the gender problem and 1 is the speaker problem\n",
    "        self.problem = problem\n",
    "    \n",
    "    def doMLP(self):\n",
    "        '''function to train mlp and tune using grid search and get results on the testing data'''\n",
    "        #initializing the parameters as asked in the manual\n",
    "        parameters = {\n",
    "        'random_state':[1],\n",
    "        'activation':['logistic'],\n",
    "        'solver':['sgd'],\n",
    "        'max_iter':[5000],\n",
    "        'learning_rate_init':[0.4,0.1,0.01],\n",
    "        'hidden_layer_sizes':[(128,64),(64,),(64,32),(32,)],\n",
    "        \n",
    "        }\n",
    "        #setting the instance\n",
    "        mlp = MLPClassifier()\n",
    "        #initializing the girdi search with the asked variables\n",
    "        clf = GridSearchCV(mlp, param_grid=parameters,scoring='f1_macro',cv=3,n_jobs=-1)\n",
    "        #fitting the mlp and tunning on training data\n",
    "        clf.fit(self.XTrain,self.YTrain)\n",
    "        #getting prediction from the best estimator on the testing data\n",
    "        self.ypred = clf.predict(self.XTest)\n",
    "        #pritnting the stats using preicitons\n",
    "        self.printStats(self.ypred)\n",
    "        \n",
    "    \n",
    "    def doSVM(self,max_iter):\n",
    "        '''function to train linear SVM and get results on the testing data'''\n",
    "        #initializing the linear svm instance\n",
    "        svm = LinearSVC(random_state=0, verbose=1, max_iter=max_iter,dual=False)\n",
    "        #fitting on the training data\n",
    "        svm.fit(self.XTrain,self.YTrain)\n",
    "        #getting prediction on the testing data\n",
    "        self.ypredsvm = svm.predict(self.XTest)\n",
    "        #printing stats using obtained predictions\n",
    "        self.printStats(self.ypredsvm)\n",
    "        \n",
    "    def doGNB(self):\n",
    "        '''function to train gaussian naive bayes and get results on the testing data'''\n",
    "        #initializing the gaussian naive bayes instance\n",
    "        mnb = GaussianNB()\n",
    "        #fitting on the training data\n",
    "        mnb.fit(self.XTrain,self.YTrain)\n",
    "        #getting predictions on the testing data\n",
    "        self.ypredgnb = mnb.predict(self.XTest)\n",
    "        #pritnting stats obtained using predictions\n",
    "        self.printStats(self.ypredgnb)\n",
    "    \n",
    "    def printStats(self,ypred):\n",
    "        '''function to print stats using predictions as asked in the project phase 3 manual'''\n",
    "        \n",
    "        #printing accuracy\n",
    "        print(\"Accuracy is:\",accuracy_score(ypred,self.YTest))\n",
    "        print()\n",
    "        \n",
    "        #depending on the problem printing the classification report\n",
    "        if self.problem==0:\n",
    "            target_names = ['M','F']\n",
    "            print(\"Printing classification report:\")\n",
    "            print(classification_report(ypred,self.YTest,target_names=target_names))\n",
    "        if self.problem==1:\n",
    "            #indexes are pushed by negative one behind\n",
    "            print(classification_report(ypred,self.YTest))\n",
    "            \n",
    "        print()\n",
    "        print(\"Printing confusion matrix\")\n",
    "        print(confusion_matrix(ypred,self.YTest))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the training classes \n",
    "trainer0 = Trainer(XTrain=XTrainp1,YTrain=YTrainp1,XTest=XTestp1,YTest=YTestp1,problem=0)\n",
    "trainer1 = Trainer(XTrain=XTrainp2,YTrain=YTrainp2,XTest=XTestp2,YTest=YTestp2,problem=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8705882352941177\n",
      "\n",
      "Printing classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.93      0.90      0.92       134\n",
      "           F       0.68      0.75      0.71        36\n",
      "\n",
      "    accuracy                           0.87       170\n",
      "   macro avg       0.80      0.83      0.81       170\n",
      "weighted avg       0.88      0.87      0.87       170\n",
      "\n",
      "\n",
      "Printing confusion matrix\n",
      "[[121  13]\n",
      " [  9  27]]\n"
     ]
    }
   ],
   "source": [
    "#training and testing mlp for gender problem\n",
    "trainer0.doMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy is: 0.8352941176470589\n",
      "\n",
      "Printing classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.92      0.87      0.90       138\n",
      "           F       0.55      0.69      0.61        32\n",
      "\n",
      "    accuracy                           0.84       170\n",
      "   macro avg       0.74      0.78      0.75       170\n",
      "weighted avg       0.85      0.84      0.84       170\n",
      "\n",
      "\n",
      "Printing confusion matrix\n",
      "[[120  18]\n",
      " [ 10  22]]\n"
     ]
    }
   ],
   "source": [
    "#training and testing mlp for svm problem\n",
    "trainer0.doSVM(max_iter=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8529411764705882\n",
      "\n",
      "Printing classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.92      0.89      0.91       135\n",
      "           F       0.62      0.71      0.67        35\n",
      "\n",
      "    accuracy                           0.85       170\n",
      "   macro avg       0.77      0.80      0.79       170\n",
      "weighted avg       0.86      0.85      0.86       170\n",
      "\n",
      "\n",
      "Printing confusion matrix\n",
      "[[120  15]\n",
      " [ 10  25]]\n"
     ]
    }
   ],
   "source": [
    "#training and testing gnb for gender problem\n",
    "trainer0.doGNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dyass\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9507042253521126\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       0.50      1.00      0.67         1\n",
      "          20       1.00      0.67      0.80         3\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       0.50      0.50      0.50         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       0.50      1.00      0.67         1\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      0.50      0.67         4\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       0.50      1.00      0.67         1\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       0.50      1.00      0.67         1\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      0.67      0.80         3\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      0.67      0.80         3\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      0.67      0.80         3\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       0.50      1.00      0.67         1\n",
      "          74       1.00      1.00      1.00         2\n",
      "          75       1.00      0.67      0.80         3\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       0.50      1.00      0.67         1\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       1.00      0.67      0.80         3\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       0.50      1.00      0.67         1\n",
      "          90       0.50      1.00      0.67         1\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       0.50      0.33      0.40         3\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       1.00      1.00      1.00         2\n",
      "          99       1.00      1.00      1.00         2\n",
      "         100       0.50      0.50      0.50         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       1.00      1.00      1.00         2\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         2\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       1.00      1.00      1.00         2\n",
      "         110       1.00      0.67      0.80         3\n",
      "         111       1.00      1.00      1.00         2\n",
      "         112       1.00      1.00      1.00         2\n",
      "         113       1.00      1.00      1.00         2\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       1.00      1.00      1.00         2\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       1.00      1.00      1.00         2\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       1.00      1.00      1.00         2\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       1.00      1.00      1.00         2\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       1.00      1.00      1.00         2\n",
      "         125       1.00      1.00      1.00         2\n",
      "         126       1.00      1.00      1.00         2\n",
      "         127       1.00      1.00      1.00         2\n",
      "         128       1.00      1.00      1.00         2\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       1.00      1.00      1.00         2\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       1.00      1.00      1.00         2\n",
      "         133       0.50      1.00      0.67         1\n",
      "         134       1.00      1.00      1.00         2\n",
      "         135       1.00      1.00      1.00         2\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       1.00      1.00      1.00         2\n",
      "         138       1.00      0.67      0.80         3\n",
      "         139       1.00      1.00      1.00         2\n",
      "         140       1.00      1.00      1.00         2\n",
      "         141       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       284\n",
      "   macro avg       0.95      0.96      0.95       284\n",
      "weighted avg       0.97      0.95      0.95       284\n",
      "\n",
      "\n",
      "Printing confusion matrix\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dyass\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#training and testing mlp for speaker problem\n",
    "trainer1.doMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy is: 0.8450704225352113\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.33      0.50         6\n",
      "           7       0.50      1.00      0.67         1\n",
      "           8       1.00      0.50      0.67         4\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      0.67      0.80         3\n",
      "          13       1.00      0.67      0.80         3\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      0.67      0.80         3\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      0.67      0.80         3\n",
      "          19       0.50      1.00      0.67         1\n",
      "          20       1.00      0.67      0.80         3\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       1.00      0.67      0.80         3\n",
      "          24       1.00      0.67      0.80         3\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       0.50      0.50      0.50         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       0.50      1.00      0.67         1\n",
      "          31       1.00      0.67      0.80         3\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       0.50      1.00      0.67         1\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      0.25      0.40         8\n",
      "          38       0.50      1.00      0.67         1\n",
      "          39       0.50      1.00      0.67         1\n",
      "          40       0.50      1.00      0.67         1\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       0.50      0.33      0.40         3\n",
      "          47       0.50      1.00      0.67         1\n",
      "          48       0.50      1.00      0.67         1\n",
      "          49       0.50      1.00      0.67         1\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      0.50      0.67         4\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       0.50      1.00      0.67         1\n",
      "          62       0.50      1.00      0.67         1\n",
      "          63       0.50      0.33      0.40         3\n",
      "          64       0.50      0.50      0.50         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       0.50      1.00      0.67         1\n",
      "          67       0.50      1.00      0.67         1\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       0.50      0.50      0.50         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      0.67      0.80         3\n",
      "          74       1.00      1.00      1.00         2\n",
      "          75       1.00      0.67      0.80         3\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       0.50      1.00      0.67         1\n",
      "          80       0.50      1.00      0.67         1\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       0.50      1.00      0.67         1\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       1.00      0.67      0.80         3\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.50      1.00      0.67         1\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       0.50      1.00      0.67         1\n",
      "          96       1.00      0.67      0.80         3\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       0.50      1.00      0.67         1\n",
      "          99       1.00      1.00      1.00         2\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.50      1.00      0.67         1\n",
      "         102       0.50      0.33      0.40         3\n",
      "         103       0.50      1.00      0.67         1\n",
      "         104       0.50      1.00      0.67         1\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         2\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       1.00      1.00      1.00         2\n",
      "         110       1.00      0.67      0.80         3\n",
      "         111       1.00      1.00      1.00         2\n",
      "         112       1.00      1.00      1.00         2\n",
      "         113       1.00      1.00      1.00         2\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       1.00      1.00      1.00         2\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       1.00      1.00      1.00         2\n",
      "         118       0.50      1.00      0.67         1\n",
      "         119       1.00      1.00      1.00         2\n",
      "         120       0.50      1.00      0.67         1\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       1.00      1.00      1.00         2\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       1.00      1.00      1.00         2\n",
      "         125       1.00      1.00      1.00         2\n",
      "         126       1.00      1.00      1.00         2\n",
      "         127       1.00      1.00      1.00         2\n",
      "         128       0.50      1.00      0.67         1\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       1.00      0.67      0.80         3\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       0.50      0.50      0.50         2\n",
      "         133       1.00      1.00      1.00         2\n",
      "         134       1.00      0.50      0.67         4\n",
      "         135       1.00      1.00      1.00         2\n",
      "         136       1.00      0.67      0.80         3\n",
      "         137       1.00      1.00      1.00         2\n",
      "         138       1.00      1.00      1.00         2\n",
      "         139       1.00      1.00      1.00         2\n",
      "         140       0.50      1.00      0.67         1\n",
      "         141       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.85       284\n",
      "   macro avg       0.85      0.88      0.84       284\n",
      "weighted avg       0.92      0.85      0.85       284\n",
      "\n",
      "\n",
      "Printing confusion matrix\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dyass\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#training and testing svm for speaker problem\n",
    "trainer1.doSVM(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9225352112676056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      0.40      0.57         5\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       0.50      1.00      0.67         1\n",
      "          20       1.00      0.67      0.80         3\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       0.50      1.00      0.67         1\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      0.50      0.67         4\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       0.50      1.00      0.67         1\n",
      "          35       1.00      0.50      0.67         4\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       0.50      1.00      0.67         1\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       0.50      1.00      0.67         1\n",
      "          41       0.50      1.00      0.67         1\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       0.50      1.00      0.67         1\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      0.50      0.67         4\n",
      "          48       1.00      0.67      0.80         3\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       0.50      1.00      0.67         1\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      0.50      0.67         4\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      0.67      0.80         3\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       0.50      1.00      0.67         1\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      0.67      0.80         3\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       0.50      1.00      0.67         1\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      1.00      1.00         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      0.50      0.67         4\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       0.50      0.33      0.40         3\n",
      "          85       1.00      0.67      0.80         3\n",
      "          86       0.50      1.00      0.67         1\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       0.50      1.00      0.67         1\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       0.50      0.50      0.50         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       0.50      1.00      0.67         1\n",
      "          99       1.00      1.00      1.00         2\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       1.00      1.00      1.00         2\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       0.50      1.00      0.67         1\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         2\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       1.00      1.00      1.00         2\n",
      "         110       1.00      1.00      1.00         2\n",
      "         111       1.00      1.00      1.00         2\n",
      "         112       1.00      0.67      0.80         3\n",
      "         113       1.00      1.00      1.00         2\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       1.00      1.00      1.00         2\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       1.00      1.00      1.00         2\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       1.00      1.00      1.00         2\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       1.00      1.00      1.00         2\n",
      "         123       0.50      1.00      0.67         1\n",
      "         124       1.00      1.00      1.00         2\n",
      "         125       1.00      1.00      1.00         2\n",
      "         126       1.00      1.00      1.00         2\n",
      "         127       1.00      1.00      1.00         2\n",
      "         128       1.00      1.00      1.00         2\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       1.00      1.00      1.00         2\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       1.00      1.00      1.00         2\n",
      "         133       1.00      1.00      1.00         2\n",
      "         134       1.00      1.00      1.00         2\n",
      "         135       1.00      1.00      1.00         2\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       1.00      1.00      1.00         2\n",
      "         138       1.00      1.00      1.00         2\n",
      "         139       1.00      1.00      1.00         2\n",
      "         140       1.00      1.00      1.00         2\n",
      "         141       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.92       284\n",
      "   macro avg       0.92      0.94      0.92       284\n",
      "weighted avg       0.96      0.92      0.93       284\n",
      "\n",
      "\n",
      "Printing confusion matrix\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dyass\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#training and testing mlp for gnb problem\n",
    "trainer1.doGNB()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
